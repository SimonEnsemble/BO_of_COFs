{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "separated-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, explained_variance_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autosklearn.regression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "elect-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69839"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['X']\n",
    "y = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['y']\n",
    "nb_data = np.size(y)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "generous-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_run(nb_training_data, nb_acquire):\n",
    "    print(\"RF run w \", nb_training_data, \"training data and\", nb_acquire, \"acquired.\")\n",
    "    # test/train split\n",
    "    X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(X, y, np.arange(nb_data), train_size=nb_training_data)\n",
    "\n",
    "    # train random forest on training data\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # hv random forest make predictions on test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # rank the test predictions\n",
    "    ids_test_ranked = np.flip(np.argsort(y_pred))\n",
    "\n",
    "    # acquire the COFs in the test set with highest predicted property\n",
    "    ids_acquire = ids_test[ids_ranked[:nb_acquire]]\n",
    "\n",
    "    # return the acquired COFs but also the trained COFs which count.\n",
    "    ids_acquire_incld_training = np.concatenate((ids_acquire, ids_train))\n",
    "    \n",
    "    assert np.size(np.unique(ids_acquire_incld_training)) == nb_training_data + nb_acquire\n",
    "    \n",
    "    return ids_acquire_incld_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "found-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUN 0\n",
      "RF run w  25 training data and 25 acquired.\n",
      "[58527 62321 45853 13274 42290 51234 35298 63189  1273 28980 11906 60007\n",
      " 55780 45555  1756 25299 37383 58011 56546 64500 69710  2201 43411 24978\n",
      "  1311  2669  7365 69716 45263  2068 57313 16539 34581 33007 39590 55529\n",
      " 26496 36215 31376 53126 38189 39054 58505 15733 42146 45071 39338 48444\n",
      " 40797  7433]\n",
      "RF run w  50 training data and 50 acquired.\n",
      "[23681 16553   431 43235 44212 69826 23494 61211 45706 36239 25495 60465\n",
      " 66325 38389 46947 23161 28664 39126 41091 34210 65566 40535 59766 49436\n",
      " 31750 63486 18088 21971  6551 45159 10703 57890 51750 64584 18927  7910\n",
      " 51565 46526 51216 51402 69408 27043 61787 12539 69609 11483 37919 48775\n",
      " 21305 36931 29135 47822 43360 18751 35274 32053 22513 44924 63898 61109\n",
      " 61769 29207 11269 57926  8550 41769 23917  7962 52619 12844 55227 52926\n",
      "  6731 40969  8781 46004 29359  8866 22996 66153  1869 64551 69355 55074\n",
      " 19210 62748 15950 57961 28854 67643 12500 69147 62542 55934 51438 24453\n",
      " 59008 39278 67280 15871]\n",
      "RF run w  75 training data and 75 acquired.\n",
      "[13213 11341 49763 58136 67364  5610 49709  9207  9678 25103 10489 25874\n",
      " 63684 58405 49690  5246 22049 15208  5783 60674 10789 69830 68742  6341\n",
      " 57375 56018 48309 58564 44631  8717 67171  4683 68571 25884 21945 51963\n",
      " 48804 63780   877 41137 14920  7034 17181 54555 67454 69451   263 32736\n",
      " 11324 34112 49859 39077 35502 41732 36843  9270 52557 25531 28474 28141\n",
      "  4433 57248  3667 30016 67625 64910 39616 49072 11714 29423  6885 40102\n",
      " 56457 29428 28617 35604 25352 33660 61446 45320  9214 13367 54314 12436\n",
      " 14745 49325 17652 23276 69249 55731 45300  8337 41074 46537 59311 64040\n",
      " 49580 20906 69234  1321 67865 12254 25007 17042 58662 16793 40172 38969\n",
      " 50937 19488 35883 36487 55096 65643 16718  6108 69547  1314  6062 34958\n",
      " 68670 41567 59951 29308 64264 53153 51362 14408  2753 33736 33021 15014\n",
      "  4308 57919 16530 26821 32909   860 60514 49632 23394 22171 67536  6709\n",
      " 38141  1285 26561 48191 44149   927]\n",
      "RF run w  100 training data and 100 acquired.\n",
      "[19750 44944 20542 60914 51657 23644 15727 42393 65125 59229  8958 40986\n",
      " 19610 31096 65900 11342 62902 67959 25891 27423 44777 34344 66766 58303\n",
      " 50889 37549 51659 38563 35956 58348 64768 30781 34824 66948 38414 47669\n",
      " 40172   539 16071 35985 65143 43701 43307  9436  9199 35636 69741 60856\n",
      " 17816 19517 48768 23906  9488 63387 64792  1980 67223 25757 47263 31577\n",
      "  2291 10192 35179 66485 11777  8203 30388 58735 43417 54592  5193 16243\n",
      "  4266 35147 64651 63069 17395 22844 22243 26412 43117  8678  1699 30044\n",
      " 65328 67769 15863 19745 56552 39981 12305 23026 47965 60795 21543 65467\n",
      "  7376 54431 67500 56312 49046 33469 66501 64597 22423 29907 45359 35392\n",
      " 20996 52004 46394    87 16389 14523 31537 68179 42556 61007 66820 51699\n",
      "   275  2848 48431 29529 68534 35880  7406 24903 66587 23928 43790 58870\n",
      " 34125 66194 52622 22731 53975 18476 30830 47551 11550 12174  6945 23702\n",
      " 54122 36777 60414 62542 24669 62156 55424 48069 33442 34536  4412  5386\n",
      " 52941 24972 49044 66693 47317 58713 54207 52501 41677 24738 56733 38721\n",
      " 64702 43819 45848 45082 37359 54521 21692 12498 14718  2852 27605 26916\n",
      " 31387 69322 62683 65654 37660 64974 54053 21592 45719 54974 62760 55776\n",
      " 42568 16511 65664 65988 27234 52337 64812 40186]\n",
      "\n",
      "\n",
      "RUN 1\n",
      "RF run w  25 training data and 25 acquired.\n",
      "[ 5341 53695 26875 37639 47133 25574 57741  1489 20926 39157 63964 11284\n",
      " 33966 42865 43901 50774 19818 61630 32464 10183 57112 50998 15869   856\n",
      " 57038  3596 34791 51713 23561  1547 46230 68907  2919 66556  7765 45594\n",
      "  2337  4692 47421 56722  4801 29746 30281 41383 43209 14247  7226 26077\n",
      "  4208 55262]\n",
      "RF run w  50 training data and 50 acquired.\n",
      "[29214 28808 60104 63744 54236 27049 47089  7221 61451  2246 14081 40548\n",
      " 14096  1306 36509 67421 21807 44698 45318 59607 22996  3903 52999 21389\n",
      "   372 49421 65281 29554 47647 10813 61872 28354 50207 52966 45802 33740\n",
      " 47177 36421 38550 50853 43386 60910 50786  2981 45924 22758  6177   917\n",
      " 40484  2818 33126 54569 66171 39851 58444 14655 22953  8819  9241 47913\n",
      " 39830  6267 19351 68421 35448 66694 67758 39371 42828 32755 40803 49860\n",
      "  2502 31829 62852 41836 31148 62208 35100 56585 22099 64869   819 69667\n",
      " 51446 54254 24801 44165 52680  9892 23994 36894 13728 32788 53452 51286\n",
      " 69178 16288 26243 63946]\n",
      "RF run w  75 training data and 75 acquired.\n",
      "[58839 52064 45618 42022 13751 17153 40388 44262 45530 52841 44141 35271\n",
      " 39814 35606 54795  4528 33910 41737  4206 31408 64114 30495 24667 48099\n",
      " 62589 67195 35875 59039 35481  8763 37216 68252 13110 45567 42642 37363\n",
      " 46733   571  6054  5221 53183 28168 41987 31781 18387 41294  9784 68823\n",
      " 16338 36570 18540 64854 42436 14964 18239 39055 49775  5416 30048 60700\n",
      " 20266 55488 14709 69246 49979 28113 13635 40892 46878 48996  6029 68195\n",
      "  3523 48778 28378 31929 13808  9626  9902 61251 21454  2856 60009 26296\n",
      "  9892 16351  4298 15296 24762 27512  6701 43365 37439 14386 25672 49413\n",
      " 24541 29420  4252 56222 42651 31463 32463 40479 59080  1299 38643 69061\n",
      " 46827 13851 20584 13624 49763 43736 13302 65766 69153 21721  3815 11481\n",
      " 40999 19846 62500 15946 61931 50892 18599 39588 16592  8736  6421 18965\n",
      " 51077 21941 61699 42931  6355 16705 20672 53900  9801 39520 68408 50053\n",
      " 33686 41812 16299 30087 29218 45967]\n",
      "RF run w  100 training data and 100 acquired.\n",
      "[24133 52295 49534  8073 51071 50507 13705 54621 24677 20882  8434 50224\n",
      " 56360  5598 20792 58330 31092  7305 55415  1134 61894 20112 45518 28728\n",
      " 37736 54777  5308 46653 45067 69723 63965 23417 37321  1853 39684 34606\n",
      " 17654 27874  5917  8596 11316 52931 69020 41380 43785 41148 63755 42138\n",
      " 63670 61023 58695 49027 26083 18875 56801 27069 33837 42077 19637 56108\n",
      " 38644 54692 56929 34967 29081 56424 42243 69444 19940  4910  7057 60933\n",
      " 66948 49541 48722 29398 26133  6244 31955 38436 62796 21756 10302 24801\n",
      " 12495 62925 25838 63488 46625 44679 13423 39299 49103  2730 16258 27231\n",
      "  1533 54900 43315 64046 13181 55591 13151  8872 42363 50097 61351 23153\n",
      " 59265 33900     3 32801 60683  8551 57044 33237 27344 43471 54577 26605\n",
      " 32222 59523 66945 22802 62300 18744 58692 13697 11285  3309  4686 58813\n",
      " 28468 47530  6512 30007 31462 41066 56535  6383 14898 59860 21717 39823\n",
      " 44607 53661  5009 19243 34836 10360 66385  5332 11496 59261 26212 64219\n",
      " 60314 56884 58461 19536 48660 59783  6671 14009  9688 26123 31959 43374\n",
      " 11348  8505 59093 28804 62857 24988 22282 16632 68302 40654 14983 66999\n",
      " 64131 19433 60607 22470 30799 33913 11425 24733 59803 62182 32186 60693\n",
      " 49310 36010 31620 40637  4061 22287 43891 56911]\n"
     ]
    }
   ],
   "source": [
    "nb_runs = 2\n",
    "nb_evals_budgets = [50 * i for i in range(1, 5)]\n",
    "for r in range(nb_runs):\n",
    "    print(\"\\n\\nRUN\", r)\n",
    "    for nb_evals_budget in nb_evals_budgets:\n",
    "        # decide how to spend the evals budget here. say 50/50\n",
    "        nb_training_data = nb_evals_budget // 2\n",
    "        nb_acquire = nb_evals_budget // 2\n",
    "        assert nb_training_data + nb_acquire == nb_evals_budget\n",
    "        \n",
    "        ids_acquired = rf_run(nb_training_data, nb_acquire)\n",
    "        print(ids_acquired)\n",
    "    torch.save({'ids_acquired': ids_acquired}, 'rf_run' + str(r) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-functionality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
