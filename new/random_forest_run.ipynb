{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "roman-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, explained_variance_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autosklearn.regression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "behind-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (69839, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69839"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['X']\n",
    "print(\"shape of X: \", np.shape(X))\n",
    "y = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['y']\n",
    "nb_data = np.size(y)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_train_test_split(X, train_size):\n",
    "    ids_train = [np.random.randint(0, nb_data)] # initialize with one random point; pick others in a max diverse fashion\n",
    "    # select remaining training points\n",
    "    for j in range(train_size - 1):\n",
    "        # for each point, compute its min distance to training set\n",
    "        min_distances_to_train_set = np.zeros((nb_data, ))\n",
    "        for i in range(nb_data):\n",
    "            # compute its distance to all points in the training set\n",
    "            distances_to_train_set = np.linalg.norm(X[i, :] - X[ids_train, :], axis=1)\n",
    "            assert np.size(distances_to_train_set) == len(ids_train)\n",
    "            min_distances_to_train_set[i] = np.min(distances_to_train_set)\n",
    "        # select point with max min distance to train set (Furthest from train set)\n",
    "        ids_train.append(np.argmax(min_distances_to_train_set))\n",
    "    assert np.size(np.unique(ids_train)) == train_size\n",
    "    ids_test = [i for i in range(nb_data) if not i in ids_train]\n",
    "    assert np.size(np.unique(ids_test)) == nb_data - train_size\n",
    "    return np.array(ids_train), np.array(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "filled-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "diversify_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frozen-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_run(nb_training_data, nb_acquire):\n",
    "    if diversify_training:\n",
    "        print(\"\\tdiverse RF run\")\n",
    "    else:\n",
    "        print(\"\\tRF run\")\n",
    "    print(\"\\teval budget\", nb_training_data + nb_acquire, \"=\", nb_training_data, \"training data and\", nb_acquire, \"acquired.\")\n",
    "    # test/train split\n",
    "    if diversify_training:\n",
    "        ids_train, ids_test = diverse_train_test_split(X, nb_training_data)\n",
    "    else:\n",
    "        ids_train, ids_test = train_test_split(np.arange(nb_data), train_size=nb_training_data)\n",
    "    \n",
    "    X_train = X[ids_train, :]\n",
    "    y_train = y[ids_train]\n",
    "    \n",
    "    X_test  = X[ids_test, :]\n",
    "    \n",
    "    # train random forest on training data\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # hv random forest make predictions on test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # rank the test predictions\n",
    "    ids_test_ranked = np.flip(np.argsort(y_pred))\n",
    "    \n",
    "    # acquire the COFs in the test set with highest predicted property\n",
    "    ids_acquire = ids_test[ids_test_ranked[:nb_acquire]]\n",
    "\n",
    "    # return the acquired COFs but also the trained COFs which count.\n",
    "    ids_acquire_incld_training = np.concatenate((ids_acquire, ids_train))\n",
    "    \n",
    "    assert np.size(np.unique(ids_acquire_incld_training)) == nb_training_data + nb_acquire\n",
    "    \n",
    "    print(\"\\tmax y acquired = \", np.max(y[ids_acquire_incld_training]))\n",
    "    return ids_acquire_incld_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collect-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval budgets:  [10, 20, 30, 50]\n",
      "budget for evals: 10\n",
      "\trun 0\n",
      "\tdiverse RF run\n",
      "\teval budget 10 = 5 training data and 5 acquired.\n",
      "\tmax y acquired =  159.96862082799998\n",
      "budget for evals: 20\n",
      "\trun 0\n",
      "\tdiverse RF run\n",
      "\teval budget 20 = 10 training data and 10 acquired.\n",
      "\tmax y acquired =  173.880645123\n",
      "budget for evals: 30\n",
      "\trun 0\n",
      "\tdiverse RF run\n",
      "\teval budget 30 = 15 training data and 15 acquired.\n",
      "\tmax y acquired =  178.997150426\n",
      "budget for evals: 50\n",
      "\trun 0\n",
      "\tdiverse RF run\n",
      "\teval budget 50 = 25 training data and 25 acquired.\n",
      "\tmax y acquired =  192.95415281799998\n"
     ]
    }
   ],
   "source": [
    "rf_res = dict()\n",
    "rf_res['nb_runs']          = 1\n",
    "rf_res['nb_evals_budgets'] = [10, 20, 30, 50] #[10 * i for i in range(1, 21)]\n",
    "print(\"eval budgets: \", rf_res['nb_evals_budgets'])\n",
    "rf_res['ids_acquired']     = [[] for b in rf_res['nb_evals_budgets']]\n",
    "for b in range(len(rf_res['nb_evals_budgets'])):\n",
    "    nb_evals_budget = rf_res['nb_evals_budgets'][b]\n",
    "    print(\"budget for evals:\", nb_evals_budget)\n",
    "    # decide how to spend the evals budget here. say 50/50\n",
    "    nb_training_data = nb_evals_budget // 2\n",
    "    nb_acquire = nb_evals_budget // 2\n",
    "    assert nb_training_data + nb_acquire == nb_evals_budget\n",
    "    for r in range(rf_res['nb_runs']):\n",
    "        print(\"\\trun\", r)\n",
    "        ids_acquired = rf_run(nb_training_data, nb_acquire)\n",
    "        rf_res['ids_acquired'][b].append(ids_acquired)\n",
    "\n",
    "if not diversify_training:\n",
    "    with open('rf_results.pkl', 'wb') as file:\n",
    "        pickle.dump(rf_res, file)\n",
    "else:\n",
    "    with open('rf_div_results.pkl', 'wb') as file:\n",
    "        pickle.dump(rf_res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-toolbox",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
