{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excessive-leader",
   "metadata": {},
   "source": [
    "# BO runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cooked-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import FixedNoiseGP, SingleTaskGP\n",
    "from gpytorch.kernels import ScaleKernel\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-compilation",
   "metadata": {},
   "source": [
    "load data from `prepare_Xy.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "selective-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69839"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['X']\n",
    "y = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['y']\n",
    "nb_data = np.size(y)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-craps",
   "metadata": {},
   "source": [
    "convert to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "promotional-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "developing-population",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69839, 12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "selected-fever",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69839, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-oxygen",
   "metadata": {},
   "source": [
    "number of COFs for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "changed-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_COFs_initialization = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "differential-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_run(nb_iterations):\n",
    "    # select initial COFs for training data randomly\n",
    "    ids_acquired = np.random.choice(np.arange((nb_data)), size=nb_COFs_initialization, replace=False)\n",
    "\n",
    "    # initialize acquired X, y\n",
    "    X_acquired = X[ids_acquired, :]\n",
    "    y_acquired = y[ids_acquired]\n",
    "    # standardize outputs\n",
    "    y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "    print(y_acquired.size())\n",
    "    \n",
    "    for i in range(nb_COFs_initialization, nb_iterations):\n",
    "        print(\"iteration:\", i)\n",
    "        # construct and fit GP model\n",
    "        model = SingleTaskGP(X_acquired, y_acquired)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_model(mll)\n",
    "\n",
    "        # compute aquisition function at each COF in the database\n",
    "        acquisition_function = ExpectedImprovement(model, best_f=y_acquired.max().item())\n",
    "        acquisition_values = acquisition_function.forward(X.unsqueeze(1))\n",
    "\n",
    "        # select COF with maximal aquisition value, which is not in the acquired set already\n",
    "        # find COF with highest value of acquisition function, not in acquired set already\n",
    "        ids_sorted_by_aquisition = acquisition_values.argsort(descending=True)\n",
    "        for id_max_aquisition_all in ids_sorted_by_aquisition:\n",
    "            if not id_max_aquisition_all.item() in ids_acquired:\n",
    "                id_max_aquisition = id_max_aquisition_all.item()\n",
    "                break\n",
    "\n",
    "        # acquire this COF\n",
    "        ids_acquired = np.concatenate((ids_acquired, np.array([id_max_aquisition])))\n",
    "\n",
    "        # update X, y acquired\n",
    "        X_acquired = torch.cat([X_acquired, X[id_max_aquisition, :].unsqueeze(0)])\n",
    "        y_acquired = y[ids_acquired, :] # start over to normalize y properly\n",
    "        y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"\\tacquired COF\", id_max_aquisition, \"with y = \", y[id_max_aquisition])\n",
    "        print(\"\\tbest y acquired:\", y[ids_acquired].max())\n",
    "    return ids_acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "working-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "iteration: 10\n",
      "\n",
      "\tacquired COF 44897 with y =  tensor([183.6189], dtype=torch.float64)\n",
      "\tbest y acquired: tensor(183.6189, dtype=torch.float64)\n",
      "[34647 35678 69727 52355 23924 10911 42976 54307 59610 62690 44897]\n",
      "torch.Size([10, 1])\n",
      "iteration: 10\n",
      "\n",
      "\tacquired COF 5174 with y =  tensor([190.2927], dtype=torch.float64)\n",
      "\tbest y acquired: tensor(190.2927, dtype=torch.float64)\n",
      "[ 5125 54841 57876 20364 16192 11446 30070 25210 15672 44596  5174]\n",
      "torch.Size([10, 1])\n",
      "iteration: 10\n",
      "\n",
      "\tacquired COF 44897 with y =  tensor([183.6189], dtype=torch.float64)\n",
      "\tbest y acquired: tensor(183.6189, dtype=torch.float64)\n",
      "[ 4354 63357 16040 50514 55005 43266 11741 11211 47269 46420 44897]\n"
     ]
    }
   ],
   "source": [
    "nb_runs = 3\n",
    "nb_iterations = 11\n",
    "for r in range(nb_runs):\n",
    "    ids_acquired = bo_run(nb_iterations)\n",
    "    print(ids_acquired)\n",
    "    torch.save({'ids_acquired': ids_acquired}, 'bo_run' + str(r) + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
